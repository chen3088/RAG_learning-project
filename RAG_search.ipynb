{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20cb36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benin\\anaconda3\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c0e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你裝好了 langchain-community 後\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b1cfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benin\\AppData\\Local\\Temp/ipykernel_21564/2887614955.py:22: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS 向量庫儲存成功：index_langchain_text2vec\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "import pandas as pd\n",
    "\n",
    "def build_faiss_from_dataframe(csv_path, output_folder, text_col=\"內文\", metadata_cols=[\"分類\", \"標題\", \"URL\"], model_name=\"shibing624/text2vec-base-multilingual\"):\n",
    "    \"\"\"\n",
    "    將 CSV 中的 DataFrame 轉成向量並建立 FAISS index，儲存在指定資料夾。\n",
    "    \"\"\"\n",
    "    # 讀入資料\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.dropna(subset=[text_col]).reset_index(drop=True)\n",
    "\n",
    "    # 建立 Document 清單（LangChain 格式）\n",
    "    docs = []\n",
    "    for _, row in df.iterrows():\n",
    "        content = str(row[text_col])\n",
    "        metadata = {col: str(row[col]) for col in metadata_cols if col in row}\n",
    "        docs.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "    # 建立 embedding 模型\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "    # 建立 FAISS 向量庫\n",
    "    vectorstore = FAISS.from_documents(docs, embedding=embeddings)\n",
    "\n",
    "    # 儲存到本地\n",
    "    vectorstore.save_local(output_folder)\n",
    "\n",
    "    print(f\"✅ FAISS 向量庫儲存成功：{output_folder}\")\n",
    "\n",
    "# ✅ 請你執行這一行時替換成實際檔案路徑\n",
    "file_path = \"EuropeTravel/【    出國事宜      】.csv\"\n",
    "build_faiss_from_dataframe(file_path, \"index_langchain_text2vec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff883f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def load_index_and_setup_qa_local(index_path=\"index_langchain_text2vec\", model_name=\"shibing624/text2vec-base-multilingual\"):\n",
    "    # 向量查詢部分\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})  # 只取前2段最相關內容\n",
    "\n",
    "    # 本地 LLM 模型，例如 FLAN-T5\n",
    "    llm_model = \"google/flan-t5-base\"  # 可換成更大模型如 \"tiiuae/falcon-rw-1b\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(llm_model)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(llm_model)\n",
    "\n",
    "    hf_pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=256)\n",
    "    llm = HuggingFacePipeline(pipeline=hf_pipe)\n",
    "\n",
    "    # 建立問答鏈\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "    return qa_chain\n",
    "\n",
    "def ask_and_log(qa_chain, question, log_path=\"qa_log.csv\"):\n",
    "    answer = qa_chain.invoke(question)\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log_entry = {\"時間\": now, \"問題\": question, \"答案\": answer}\n",
    "\n",
    "    try:\n",
    "        df_log = pd.read_csv(log_path)\n",
    "    except FileNotFoundError:\n",
    "        df_log = pd.DataFrame(columns=[\"時間\", \"問題\", \"答案\"])\n",
    "\n",
    "    df_log = pd.concat([df_log, pd.DataFrame([log_entry])], ignore_index=True)\n",
    "    df_log.to_csv(log_path, index=False)\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4013dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '有哪些歐洲火車查詢網站？', 'result': ''}\n"
     ]
    }
   ],
   "source": [
    "qa = load_index_and_setup_qa_local()\n",
    "ans = ask_and_log(qa, \"有哪些歐洲火車查詢網站？\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c500f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入來源 metadata、一併顯示標題/分類/URL，我也可以幫你擴充版本，是否要加上這部分"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
